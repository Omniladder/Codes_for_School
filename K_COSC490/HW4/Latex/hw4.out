\BOOKMARK [1][-]{section.1}{Concepts, intuitions and big picture}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Multiple-choice questions. }{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Short answer questions}{section.1}% 3
\BOOKMARK [1][-]{section.2}{Softmax Smackdown: Squishing the Competition}{}% 4
\BOOKMARK [2][-]{subsection.2.1}{Softmax gradient}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.2}{Softmax temperature}{section.2}% 6
\BOOKMARK [1][-]{section.3}{Backprop Through Residual Connections}{}% 7
\BOOKMARK [1][-]{section.4}{Programming}{}% 8
\BOOKMARK [2][-]{subsection.4.1}{Tokenization Algorithms}{section.4}% 9
\BOOKMARK [3][-]{subsubsection.4.1.1}{What is Tokenization?}{subsection.4.1}% 10
\BOOKMARK [3][-]{subsubsection.4.1.2}{Character-based tokenization}{subsection.4.1}% 11
\BOOKMARK [3][-]{subsubsection.4.1.3}{Subword Tokenizaiton}{subsection.4.1}% 12
\BOOKMARK [3][-]{subsubsection.4.1.4}{Complete the BPE Algorithm}{subsection.4.1}% 13
\BOOKMARK [3][-]{subsubsection.4.1.5}{Running BPE on a subset of Wikipedia}{subsection.4.1}% 14
\BOOKMARK [3][-]{subsubsection.4.1.6}{Additonal Readings: Other Tokenization Algorithms}{subsection.4.1}% 15
\BOOKMARK [2][-]{subsection.4.2}{Fixed-Window MLP Language Models}{section.4}% 16
\BOOKMARK [3][-]{subsubsection.4.2.1}{Data Loading and Preprocessing}{subsection.4.2}% 17
\BOOKMARK [3][-]{subsubsection.4.2.2}{Build our LM}{subsection.4.2}% 18
\BOOKMARK [3][-]{subsubsection.4.2.3}{Train and Evaluate the LM}{subsection.4.2}% 19
\BOOKMARK [3][-]{subsubsection.4.2.4}{Sample From a Pre-trained LM}{subsection.4.2}% 20
